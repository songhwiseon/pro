import requests
from bs4 import BeautifulSoup

# ğŸ”¹ ë„¤ì´ë²„ ë‰´ìŠ¤ URL ëª©ë¡
NEWS_URLS = {
    "ì² ê°•": "https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=%EC%B2%A0%EA%B0%95",
    "ë°˜ë„ì²´": "https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=%EB%B0%98%EB%8F%84%EC%B2%B4",
    "ìë™ì°¨": "https://search.naver.com/search.naver?where=news&ie=utf8&sm=nws_hty&query=%EC%9E%90%EB%8F%99%EC%B0%A8",
    "ì •ì¹˜": "https://news.naver.com/section/100",
    "ê²½ì œ": "https://news.naver.com/section/101"
}

def get_news(category):
    """ ì£¼ì œë³„ ìµœì‹  ë‰´ìŠ¤ 10ê°œ í¬ë¡¤ë§ """
    if category not in NEWS_URLS:
        return []

    url = NEWS_URLS[category]
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "html.parser")

    news_list = []

    if category in ["ì² ê°•", "ë°˜ë„ì²´", "ìë™ì°¨"]:
        # ğŸ”¹ ë„¤ì´ë²„ ê²€ìƒ‰ ë‰´ìŠ¤ ê²°ê³¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        items = soup.select(".news_area .news_tit")[:10]  # ìµœëŒ€ 10ê°œ ê°€ì ¸ì˜¤ê¸°
        for item in items:
            title = item.text.strip()
            link = item["href"]
            news_list.append({"title": title, "link": link})

    elif category in ["ì •ì¹˜", "ê²½ì œ"]:
        # ğŸ”¹ ë„¤ì´ë²„ ë‰´ìŠ¤ í˜ì´ì§€ í—¤ë“œë¼ì¸ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        items = soup.select(".sa_text_strong")[:10]  # ìµœëŒ€ 10ê°œ
        for item in items:
            title = item.text.strip()
            link = item.find_parent("a")["href"]
            news_list.append({"title": title, "link": link})

    return news_list


# print(get_news("ì² ê°•"),'ë')
# print(get_news("ë°˜ë„ì²´"),'ë')
# print(get_news("ì •ì¹˜"),'ë')
# print(get_news("ê²½ì œ"),'ë')
# print(get_news("ìë™ì°¨"),'ë')

